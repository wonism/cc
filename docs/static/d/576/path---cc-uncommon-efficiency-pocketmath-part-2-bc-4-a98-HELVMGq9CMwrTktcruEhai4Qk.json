{"pageContext":{"id":"581535","parent":"__SOURCE__","slug":"uncommon-efficiency-pocketmath-part-2","internal":{"contentDigest":"ba31f17a82d86d89494049e95d47e5db","type":"ContentCoPost","owner":"default-site-plugin"},"children":[],"title":"5 things we did to make our servers and engineers more efficient","preview":{"source":"https://cdn.techinasia.com/wp-content/uploads/2018/10/image003-750x562.png","attachment_meta":{"width":null,"height":null,"sizes":{}}},"createdAt":"2018-10-05T02:00:33","content":"<div id=\"attachment_583565\" class=\"wp-caption aligncenter\">\n<img class=\"size-large wp-image-583565\" src=\"https://cdn.techinasia.com/wp-content/uploads/2018/10/image003-750x562.png\" alt=\"pocketmath-engineering\" width=\"750\" height=\"562\"><p class=\"wp-caption-text\">Vishnu Sreekumar, dev-ops, systems engineer at Pocketmath</p>\n</div>\n<p>In our <a href=\"https://www.techinasia.com/talk/uncommon-efficiency-pocketmath-part-1\">previous article</a>, we introduced the idea of uncommon efficiency, which is about unlocking potential by seeking out surprisingly low but often overlooked scale and productivity barriers.</p>\n<p>In this article, we’ll take a closer look at how the concept helped us find just the right mix of productivity for both our servers and engineers.</p>\n<p>A commercially viable mobile DSP like our company must take in a large swath of ad impressions. With naive approaches, server budgets can stretch into seven or eight figures a month.</p>\n<p>To achieve both computational and human efficiency, we went back to the basics—independent decisions that tie back to computer science theory and a deep understanding of problems.</p>\n<h2><strong>When speed matters</strong></h2>\n<p>In Walter Isaacson’s biography of Steve Jobs, he relates <a href=\"https://www.techinasia.com/you-outbully-him-employees-stood-steve-jobs\">how the Apple CEO motivated engineer Larry Kenyon</a> to make the Mac boot faster:</p>\n<blockquote><p>“Jobs went to a whiteboard and showed that if there were 5 million people using the Mac, and it took 10 seconds extra to turn it on every day, that added up to 300 million or so hours per year […] equivalent [to] at least 100 lifetimes saved per year.”</p></blockquote>\n<p>Actually, Jobs’ numbers were <a href=\"https://blog.erictucker.com/2018/09/24/math-pierces-steve-jobs-reality-distortion-field-after-35-years/\" target=\"_blank\" rel=\"nofollow noopener\">an order of magnitude too high</a>. But the lesson rings true, and we took it to heart.</p>\n<p>Performance optimizations get down to the nitty gritty, usually focusing on things that happen very, very often. To go fast, we looked at the plainest details. For instance:</p>\n<ul>\n<li>Are the things that run most frequently receiving the most attention to make them faster?</li>\n<li>Are we managing concurrent access to resources efficiently?</li>\n<li>Is one process preventing another from running in parallel?</li>\n<li>Are the way things are organized in memory appropriate for the size of the data?</li>\n</ul>\n<blockquote class=\"pull-quote\">Human programmers still have jobs for good reasons.</blockquote>\n<p>While modern programming tools (compilers) do some of the work, they cannot overcome a fundamentally inefficient algorithm. Human programmers still have jobs for good reasons.</p>\n<p>Shaving a few microseconds off an operation may not seem like much, but a 100 percent speed improvement in some tiny component might cut the overall server bill by 20 percent. Those huge savings are surprisingly achievable by looking at everyday programming problems.</p>\n<h2><strong>Being selective with technology frameworks and standards</strong></h2>\n<h3><strong>Ruby on Rails</strong></h3>\n<p>Our software components largely fit into categories favoring either (1) maximum efficiency for servers or (2) maximum productivity for human programmers.</p>\n<p>The user interface components fit into the second. As such, the web console our users see is built on <a href=\"https://rubyonrails.org/\" target=\"_blank\" rel=\"nofollow noopener\">Ruby on Rails</a>. The language is slow for computers but fast for humans. With the Rails framework, a single line of code may quietly automate a great deal, including multiple database queries. The framework makes assumptions that reduce human effort because the computer covers every possibility—though at a computational cost.</p>\n<p>Given the relatively small scale of such components, extra server resources to cover inefficiencies don’t break the bank, and we quickly adapt the UI to advertiser needs.</p>\n<p>Bidders, which see in excess of half a million impression opportunities per second, fit predominantly into the first category. Crunching big data is also category one. For these, machine efficiency is favored over that of humans. However, <a href=\"https://www.techinasia.com/companies/pocketmath\">Pocketmath</a> doesn’t have thousands of engineers, so there is a careful trade-off.</p>\n<h3><strong>C++</strong></h3>\n<p>For extreme throughput, C++ is a common language, but we didn’t want something that would—in the words of our engineering alumnus Andy Kurnia—“get our feet shot.” Languages like C++ are fast as they give programmers control over every aspect. However, they are not ideal for developer productivity or system reliability.</p>\n<p>In C++, every time a programmer allocates memory, they must later de-allocate. If not, available memory will disappear. A single mistake piles on quickly, and at RTB scale, servers can crash in minutes!</p>\n<h3><strong>A secret language</strong></h3>\n<p>Support was another consideration, which ruled out many less established or esoteric languages (including the intriguing <a href=\"https://dlang.org/\" target=\"_blank\" rel=\"nofollow noopener\">D</a>). We needed a language that engineers knew or could easily learn. The language also needed to have mature add-ons, effective communication capabilities, convenient programming tools, and established methods for quality assurance.</p>\n<p>We decided on a language (a secret for now) that provides the speed to stay within our server budgets, without bogging down our software engineers in a minefield of tedious, avoidable details.</p>\n<p>The sweet spot unleashed our creativity. We believe in using the right tool for the job.</p>\n<h2><strong>Data locality</strong></h2>\n<p>How do we marry the advantages of running everything in one place with the scale we require? We process data where it lives.</p>\n<p>Often, computers crunch intermediate results which are required as inputs to the next step. If each step requires accessing data over a network with even a cost as small as one millisecond, doing it 10 times is already 10 milliseconds of overhead. If everything is on the same machine, these “round trips” essentially disappear. As the total computation time without network round trips is often below one millisecond, local data enables a dramatic improvement.</p>\n<p>Data locality allows programmers to be faster too. Working with data in local memory is often easier than querying other subsystems. There are fewer moving parts for programmers to wrangle.</p>\n<p>Managing data to improve locality requires a mindset that permeates the software’s entire design. As the approach goes against several conventions, it does require a dose of different thinking. We started thinking this way on day one, and we’re still doing it today.</p>\n<h2>Living well in the cloud</h2>\n<p>In 2012, there were doubts about placing a high-volume, real-time system in the cloud. But back then, we didn’t have the capital to buy farms of servers. Likewise, we needed flexibility while learning and building. So, the cloud was a choice of necessity, and it was a good decision.</p>\n<p>We architected our systems when in-cloud network latencies and server performance were less consistent. We built on the assumption that each component’s performance might vary, and we optimized everything that might traverse a network. The trial by fire wasn’t always fun, but we couldn’t be happier about <a href=\"https://aws.amazon.com/solutions/case-studies/pocketmath/\" target=\"_blank\" rel=\"nofollow noopener\">the results</a>.</p>\n<h2><strong>At the speed of the wire</strong></h2>\n<p>“Wire speed” describes data traveling at the ideal speed with which optimum network hardware can push data across wires. XML and JSON data formats (familiar to developers) are dead slow compared to Google’s <a href=\"https://developers.google.com/protocol-buffers/\" target=\"_blank\" rel=\"nofollow noopener\">Protocol Buffers</a> that ditch human readability for ultra-compact representations of data.</p>\n<p>Early on, we rolled our own ultra-compact formats. A year or two later, RTB exchanges embraced Protocol Buffers to communicate with DSPs.</p>\n<p style=\"text-align: center;\">***</p>\n<p>We have revealed several areas that reduced server cost and improved the agility of our team. Among all these nuts and bolts exists a duality of focus: speed without compromise.</p>\n<p>We apply the savings to put the pedal to the metal for the advertiser. Uncommon efficiency lets us do more during the bidding process to drive a superior experience and results.</p>","categories":[{"id":"43226","name":"Community","slug":"community"},{"id":"43483","name":"Engineering","slug":"engineering"},{"id":"39696","name":"Startups","slug":"startups"}],"author":{"name":"Eric Tucker","image":"https://cdn.techinasia.com/wp-content/authors/210456.png?v=1538125894"},"seo":{"title":"5 things we did to make our servers and engineers more efficient","description":"For a mobile ad platform like us, server budgets can stretch up to eight figures a month. We had to go back to the basics.","image":"https://cdn.techinasia.com/wp-content/uploads/2018/10/image003-750x562.png"}}}