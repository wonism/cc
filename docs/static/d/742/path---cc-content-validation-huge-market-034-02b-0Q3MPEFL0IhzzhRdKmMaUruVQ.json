{"pageContext":{"id":"581782","parent":"__SOURCE__","slug":"content-validation-huge-market","internal":{"contentDigest":"adc9960a70a9afc2e5d248f9f96dbc7f","type":"ContentCoPost","owner":"default-site-plugin"},"children":[],"title":"Opinion: Content validation is hard to pull off, but it’s a huge market opportunity","preview":{"source":"https://cdn.techinasia.com/wp-content/uploads/2018/10/26820.jpg","attachment_meta":{"width":null,"height":null,"sizes":{}}},"createdAt":"2018-10-02T06:30:22","content":"<div id=\"attachment_582915\" class=\"wp-caption aligncenter\">\n<img class=\"size-full wp-image-582915\" src=\"https://cdn.techinasia.com/wp-content/uploads/2018/10/26820.jpg\" alt=\"\" width=\"4168\" height=\"3334\"><p class=\"wp-caption-text\">Photo credit: <a href=\"https://www.freepik.com/free-vector/characters-of-people-holding-website-icons-illustration_2921438.htm\" target=\"_blank\" rel=\"nofollow noopener\">Rawpixel</a></p>\n</div>\n<p>By now, you’ve probably seen <a href=\"https://www.youtube.com/watch?v=cQ54GDm1eL0\" target=\"_blank\" rel=\"nofollow noopener\">the fake video</a> of Barack Obama calling Donald Trump “a total and complete dipsh*t.”  The voice may not be exactly right, but the clip—which took <a href=\"https://www.buzzfeed.com/craigsilverman/obama-jordan-peele-deepfake-video-debunk-buzzfeed?utm_term=.apO6G6m14#.km7lwlYe9\" target=\"_blank\" rel=\"nofollow noopener\">a team of video pros at BuzzFeed</a> 56 hours to create—vividly illustrates the nascent threat of deepfakes (i.e. digitally altered videos that can make anyone say anything).</p>\n<p>Deepfake technology is already being widely (and controversially) used to insert celebrity faces into pornography. But it’s not hard to see how dangerous it may prove in the political realm. The threat is so real that DARPA, the US defense agency responsible for emerging military technology, has already assembled an <a href=\"https://www.darpa.mil/program/media-forensics\" target=\"_blank\" rel=\"nofollow noopener\">official media forensics lab</a> to sniff out fakes.</p>\n<p>Of course, forged videos aren’t the only threat on the fake news front. There are also plain old fake headlines and news stories.</p>\n<p>In the end, we’re left deeply uncertain about who and what to trust.</p>\n<p>As someone who has built a career in social media, I find this worrying. I have tremendous faith in the power of social channels to create connection and open up dialogue, but the spread of fake content is a real and growing threat.</p>\n<p>How do we restore trust and confidence in online content? To me, the way forward isn’t just an algorithm tweak or a new set of regulations. This challenge is far too complex for that. We’re talking, at root, about faith in what we see and hear online, about trusting the raw data that informs the decisions of individuals, companies, and whole countries.</p>\n<p>The time for a band-aid fix has long passed. Instead, we may be talking about the digital era’s next growth industry: content validation.</p>\n<h2>The burgeoning content validation industry</h2>\n<p>Interestingly, we’re already seeing a flurry of activity in this arena, as the arms race between fakers and detectives accelerates.</p>\n<p>The deepfake phenomenon, in particular, has inspired a growing technological response, <a href=\"https://www.axios.com/the-impending-war-over-deepfakes-b3427757-2ed7-4fbc-9edb-45e461eb87ba.html\" target=\"_blank\" rel=\"nofollow noopener\">outlined recently by Axios’ Kaveh Waddell</a>.</p>\n<p>The startup Trupic, which has just attracted more than US$10 million in funding from the likes of Reuters, has <a href=\"https://techcrunch.com/2018/06/20/detect-deepfake/\" target=\"_blank\" rel=\"nofollow noopener\">set its sights</a> on sniffing out details like eye reflectivity and hair placement, which are nearly impossible to fake across the thousands of frames in a video.</p>\n<p>Gfycat, the gif-hosting platform, uses <a href=\"https://www.wired.com/story/gfycat-artificial-intelligence-deepfakes/\" target=\"_blank\" rel=\"nofollow noopener\">AI-powered tools that check for anomalies</a> to identify and pull down offending clips on its site.</p>\n<p>On the academic and research front, scientists at Los Alamos are building algorithms that hunt out repeated visual elements (a tell-tale sign of video manipulation), while researchers from the University at Albany have developed a system that <a href=\"https://arxiv.org/pdf/1806.02877.pdf\" target=\"_blank\" rel=\"nofollow noopener\">monitors video blinking patterns</a>. DARPA and its media forensics team, meanwhile, look for inconsistencies in lighting on AI-generated faces.</p>\n<h2>The problem of fake text-based stories</h2>\n<p>Trickier still, however, is flagging fake and biased text-based news stories—the kind of content that’s easy to make and likeliest to find its ways into our social streams.</p>\n<p>There’s little technical trickery required here, just an old-fashioned ability to tell convincing lies and use language to manipulate readers’ own biases and emotions. Perhaps for that reason, these fake stories seem to avoid machine detection and often require direct human intervention to suss out.</p>\n<p>Facebook, for all its technical sophistication, has resorted to partnering with <a href=\"https://newsroom.fb.com/news/2018/06/hard-questions-fact-checking/\" target=\"_blank\" rel=\"nofollow noopener\">a growing army of human fact checkers</a> to vet content on its platform in the wake of Cambridge Analytica and the 2016 election crises.</p>\n<p>Posts flagged as false by users (or by machine learning) are forwarded on to one of 25 fact-checking partners in 14 countries. Content deemed false is demoted by Facebook, which pushes it lower in the news feed, evidently reducing future views by more than 80 percent.</p>\n<p>This manual, piecemeal approach admittedly leaves a lot to be desired: standards vary by fact-checking organization, and even patently fake stories may go viral before Facebook has a chance to demote them. Not to mention, the <a href=\"https://zephoria.com/top-15-valuable-facebook-statistics/\" target=\"_blank\" rel=\"nofollow noopener\">sheer scale</a> frustrates human intervention: 510,000 comments are posted and 136,000 photos are uploaded per minute.</p>\n<p>It’s little wonder there aren’t enough fact-checkers to review all false claims.</p>\n<h2>The future of trust</h2>\n<p>Is there a better way to address this problem? There has to be.</p>\n<p>Will it be easy? Nope.</p>\n<p>This is where ingenuity and market opportunity need to come together. For instance, can we find a way to leverage <a href=\"https://moz.com/learn/seo/domain-authority\" target=\"_blank\" rel=\"nofollow noopener\">domain authority</a>—the search engine ranking scores that serve as a rough proxy for “trustworthiness”—in vetting content shared on social media? (An outlet like <em>The New York Times</em>, for instance, which has a domain authority of 99/100, would be ranked as highly trusted.)</p>\n<p>This approach is scalable but far from perfect since domain authority is rooted largely in backlinks rather than factual correctness.</p>\n<p>Could we take a cue from HTTPS protocol? The trusted lock symbol next to the address bar on our browsers offers instant assurance that sites we’re visiting—like banks or online stores—are secure and our sensitive data is safe.</p>\n<p>It’s not hard to imagine how useful this concept would be in the world of content: I’m picturing a nifty little badge on videos, photos, and stories that have been verified as true and factually correct. The challenge is that HTTPS is merely an assurance of encryption. Vouching for data accuracy is a thornier issue altogether and far more complex from a technical and human standpoint.</p>\n<p>What about blockchain? The idea of an immutable ledger in the cloud, tracing the origin of all content to its source, definitely sounds appealing. Users could compare versions of videos or images to check for modifications, and watermarks would serve as a badge of quality. (Indeed, this is largely the idea behind the <a href=\"https://truepic.com/\" target=\"_blank\" rel=\"nofollow noopener\">Truepic app</a>.) But here, too, the question is whether this can be applied to text-based content, where the intent to deceive leaves fewer technical traces.</p>\n<p style=\"text-align: center;\">***</p>\n<p>Ultimately, comprehensive content validation is far easier to imagine than to pull off in real life.</p>\n<p>Once upon a time, we had a pretty great system for this. It was called journalism.</p>\n<p>For all of their limits and flaws, news outlets aspired to certain standards of accuracy, and professionals dedicated their lives to upholding them. With the advent of the internet and social media, however, those traditional gatekeepers are long gone. Anyone can create news now. Anyone can spread false information. Anyone can cast aspersions on what we know to be real and true.</p>\n<p>But here’s why I’m encouraged. The backbone of the digital economy—which, increasingly, is <em>the only economy</em>—is information exchange.</p>\n<p>When that information loses its validity, that’s a huge problem. But it’s also a huge market opportunity. Content validation is a void waiting to be filled, and it may just represent one of the next great digital waves.</p>\n<p><em>This article was first published on the <a href=\"https://www.linkedin.com/pulse/next-tech-boom-content-validation-ryan-holmes/\" target=\"_blank\" rel=\"nofollow noopener\">author’s LinkedIn account</a>.</em></p>","categories":[{"id":"43226","name":"Community","slug":"community"},{"id":"7225","name":"Opinion","slug":"opinion-editorial"},{"id":"14","name":"Social Media","slug":"social-media"}],"author":{"name":"Ryan Holmes","image":"https://cdn.techinasia.com/wp-content/authors/69294.jpg?v=1453349162"},"seo":{"title":"Opinion: Content validation is hard to pull off, but it's a huge market opportunity","description":"How do we restore trust and confidence in online content? The way forward isn’t just an algorithm tweak or a new set of regulations.","image":"https://cdn.techinasia.com/wp-content/uploads/2018/10/26820.jpg"}}}